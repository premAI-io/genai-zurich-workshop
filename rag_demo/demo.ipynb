{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9165d7f7-b2fe-418b-84f8-4de68cc3475d",
   "metadata": {},
   "source": [
    "## Load the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "260c1eeb-8d86-473a-85f6-eeeda115696c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/rag_demo/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239f333c-d331-4dc6-8e9d-e9e2ac177442",
   "metadata": {},
   "source": [
    "## Define the global constants\n",
    "\n",
    "Note that this runs completely offline.\n",
    "1. We use the `Alibaba-NLP/gte-large-en-v1.5` model as the embedding model from HuggingFace.\n",
    "2. We use the `premai-io/prem-1B-chat` for the chat model instead of OpenAI (GPT 3.5 or GPT 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95ff71bf-d496-40ac-9f54-9efc2d167420",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "EMBED_MODEL_NAME = \"Alibaba-NLP/gte-large-en-v1.5\"\n",
    "CHAT_MODEL_NAME = 'premai-io/prem-1B-chat'\n",
    "\n",
    "CHUNK_SIZE = 400\n",
    "CHUNK_OVERLAP = 40\n",
    "\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the users's question. If you can't find the answer in the context, just say that you don't know. Keep the answer short and concise.\n",
    "\n",
    "Context: ```\n",
    "{context}\n",
    "```\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd97551-bcad-411c-8704-05eeb8fb44ba",
   "metadata": {},
   "source": [
    "## Embed the docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440f9221-5673-4208-bb7d-aefe1a390ff2",
   "metadata": {},
   "source": [
    "#### Load the docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "063ea61b-f9ad-4db9-b2eb-6dbbe69ec465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:38<00:00,  1.92s/it]\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "\n",
    "for f in tqdm(list(Path('docs').iterdir())):\n",
    "    if f.suffix == '.pdf':\n",
    "        loader = PyPDFLoader(f)\n",
    "        docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f38e37-aba0-42fc-ac7d-befb111b3beb",
   "metadata": {},
   "source": [
    "#### Split the docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d024adff-1511-4d34-88ca-229b71dbd112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CHAT_MODEL_NAME)\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(tokenizer, chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9dba8d-a9fb-4649-83f6-51c91cff196f",
   "metadata": {},
   "source": [
    "#### Create the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7720b630-4e57-4605-9067-84f8f8ee0782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/rag_demo/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_kwargs = {'device': DEVICE, 'trust_remote_code': True}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embedding_gen = HuggingFaceEmbeddings(\n",
    "    model_name=EMBED_MODEL_NAME,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embedding_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f014f43-20f7-4cb7-adb2-d5a50cc13dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "\n",
    "def generate_result(model, tokenizer, messages, terminators):\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    # Generate\n",
    "    inputs = tokenizer(prompt, return_attention_mask=False, return_tensors=\"pt\", add_special_tokens=False)\n",
    "    input_ids = inputs['input_ids']\n",
    "    input_ids = input_ids.to(model.device)\n",
    "    res = model.generate(input_ids=input_ids, max_new_tokens=1000, pad_token_id=tokenizer.pad_token_id, eos_token_id=terminators, do_sample=False)\n",
    "    generated_text = tokenizer.decode(res[0][input_ids.shape[1]:], skip_special_tokens=True).strip()\n",
    "    return generated_text\n",
    "\n",
    "\n",
    "def ask_question(ques, vectorstore, model, tokenizer, terminators):\n",
    "    docs = vectorstore.similarity_search(ques, k=7)\n",
    "    relevant_context = format_docs(docs)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [(\"system\", RAG_SYSTEM_PROMPT), (\"user\", \"{input}\")]\n",
    "    )\n",
    "    messages = prompt.invoke({'context': relevant_context, 'input': 'hi'}).messages\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': messages[0].content},\n",
    "        {'role': 'user', 'content': messages[1].content},\n",
    "    ]\n",
    "    res = generate_result(model, tokenizer, messages, terminators)\n",
    "    return {'response': res, 'relevant_docs': [d.page_content for d in docs]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a006f7e7-fd31-49c4-accb-75386cdd6f70",
   "metadata": {},
   "source": [
    "## Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f43fe65-36ac-4fcb-92af-61f99fae5e11",
   "metadata": {},
   "source": [
    "#### Load the `premai-io/prem-1B-chat` model from Huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae8adaf3-815b-41ba-8f5f-e3dc22a4d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained('premai-io/prem-1B-chat', torch_dtype=torch.bfloat16)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Setup terminators\n",
    "terminators = [tokenizer.eos_token_id, tokenizer.encode('<|eot_id|>', add_special_tokens=False)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18a5e17-74e4-4e12-8e04-60b12c59d7f9",
   "metadata": {},
   "source": [
    "#### Ask the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47e49b82-e7dd-4f05-870e-28ec2b8adbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"How does the proposed directive address the challenges related to the application of the Product Liability Directive (PLD) to products in the modern digital economy, specifically in relation to software and AI-enabled products?\",\n",
    "    \"What are the proposed changes to the limitations on making compensation claims, such as the threshold for property damage and the period of liability for manufacturers?\",\n",
    "    \"How does the NIS 2 Directive (Directive (EU) 2022/2555) ensure a high common level of cybersecurity across the Union, and what are the specific obligations for Member States in terms of national cybersecurity strategies?\",\n",
    "    \"How does the Data Act ensure the protection of trade secrets when data holders are required to share data with users or third parties, and what measures can data holders take to preserve the confidentiality of their trade secrets?\",\n",
    "    \"What measures are proposed to ease the burden of proof for injured persons in complex cases involving pharmaceuticals, smart products, or AI-enabled products?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d716a62d-4072-440d-a937-9280424d09cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: How does the proposed directive address the challenges related to the application of the Product Liability Directive (PLD) to products in the modern digital economy, specifically in relation to software and AI-enabled products?\n",
      "\n",
      "Assistant Response 1: hi,\n",
      "\n",
      "the proposal is to modernize rules on machinery, radio equipment and general product safety in the european union. The proposal aims to ensure that when products cause harm, they are liable to compensation. The proposal also aims to ensure that when products cause harm, they are liable to compensation. The proposal is in line with the commission's priorities to make the european union fit for the digital age and to build a future-ready economy that works for people. The proposal complements the digital -by-default modernization process that the commission is undertaking. The proposal is in line with the commission's priorities to make the european union fit for the digital age and to build a future-ready economy that works for people.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Question 2: What are the proposed changes to the limitations on making compensation claims, such as the threshold for property damage and the period of liability for manufacturers?\n",
      "\n",
      "Assistant Response 2: The proposal is to modernize product liability rules in Europe by ensuring that they are fit for the digital age. The proposal aims to facilitate access to information, innovation, and innovation, while also ensuring consumer protection. The proposal is based on the Commission's priorities to make Europe fit for the digital age and to build a future-ready economy that works for people. The proposal aims to modernize product liability rules in Europe by ensuring that they are fit for the digital age. The proposal is based on the Commission's priorities to make Europe fit for the digital age and to build a future-ready economy that works for people. The proposal is also based on the Commission's priorities to ensure that the rules are fit for the digital age and to build a future-ready economy that works for people.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Question 3: How does the NIS 2 Directive (Directive (EU) 2022/2555) ensure a high common level of cybersecurity across the Union, and what are the specific obligations for Member States in terms of national cybersecurity strategies?\n",
      "\n",
      "Assistant Response 3: This text is meant purely as a documentation tool and has no legal effect. The Union's institutions do not assume any liability for its contents.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Question 4: How does the Data Act ensure the protection of trade secrets when data holders are required to share data with users or third parties, and what measures can data holders take to preserve the confidentiality of their trade secrets?\n",
      "\n",
      "Assistant Response 4: hi, this is a great question! I'll try to help you with the answer. The text you provided is from the European Union's directive on the protection of undisclosed know-how and business information (2016/943). The directive is a regulation that sets out rules for the protection of undisclosed know-how and business information. The directive is part of the EU's data protection and privacy framework, which aims to protect personal data and ensure that it is used only for legitimate purposes. The directive is intended to protect the confidentiality of trade secrets and business information, which are important for businesses to protect their competitive advantage. The directive also sets out measures to protect trade secrets and business information, such as confidentiality agreements, technical and organizational measures, and model contractual terms. The directive is intended to ensure that trade secrets and business information are not disclosed without the consent of the holder, and that measures are taken to prevent the disclosure of trade secrets and business information.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Question 5: What measures are proposed to ease the burden of proof for injured persons in complex cases involving pharmaceuticals, smart products, or AI-enabled products?\n",
      "\n",
      "Assistant Response 5: hi,\n",
      "the user has not provided any information about the proposed directive. Please provide more information about the proposed directive.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, ques in enumerate(questions):\n",
    "    res = ask_question(ques, vectorstore, model, tokenizer, terminators)\n",
    "    print(f'Question {i+1}: {ques}')\n",
    "    print()\n",
    "    print(f\"Assistant Response {i+1}: {res['response']}\")\n",
    "    print()\n",
    "    print('-'*100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9d75e8-baf3-4cfb-adf8-41c2725bde2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b0a68a-9db8-48be-89a5-97d5dcad5462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
